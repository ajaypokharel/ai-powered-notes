{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utkXHuA0yyjw"
   },
   "source": [
    "# Deep Speech\n",
    "\n",
    "(DeepSpeech on Github)[https://github.com/mozilla/DeepSpeech]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_YZL5X8gzAv1"
   },
   "source": [
    "#### Installing Package and downloading Models and Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Piv8gV7eeSYc",
    "outputId": "7390e060-272d-433c-fb11-0306810cb764"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepspeech in ./venv/lib/python3.8/site-packages (0.9.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in ./venv/lib/python3.8/site-packages (from deepspeech) (1.24.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install deepspeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cb7SwfaKeeiW",
    "outputId": "09c3202c-40b5-4ff1-9fd2-77f2888144c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-09-06 01:11:41--  https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.pbmm\n",
      "Resolving github.com (github.com)... 140.82.114.3\n",
      "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/60273704/8b25f180-3b0f-11eb-8fc1-de4f4ec3b5a3?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230906%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230906T061141Z&X-Amz-Expires=300&X-Amz-Signature=f3919649106ad8e162f28d66a54a0cf90026fd7efbf9d12d1497db85f0f11702&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=60273704&response-content-disposition=attachment%3B%20filename%3Ddeepspeech-0.9.3-models.pbmm&response-content-type=application%2Foctet-stream [following]\n",
      "--2023-09-06 01:11:41--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/60273704/8b25f180-3b0f-11eb-8fc1-de4f4ec3b5a3?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230906%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230906T061141Z&X-Amz-Expires=300&X-Amz-Signature=f3919649106ad8e162f28d66a54a0cf90026fd7efbf9d12d1497db85f0f11702&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=60273704&response-content-disposition=attachment%3B%20filename%3Ddeepspeech-0.9.3-models.pbmm&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 188915987 (180M) [application/octet-stream]\n",
      "Saving to: ‘deepspeech-0.9.3-models.pbmm.1’\n",
      "\n",
      "deepspeech-0.9.3-mo 100%[===================>] 180.16M  42.6MB/s    in 4.9s    \n",
      "\n",
      "2023-09-06 01:11:46 (36.5 MB/s) - ‘deepspeech-0.9.3-models.pbmm.1’ saved [188915987/188915987]\n",
      "\n",
      "--2023-09-06 01:11:46--  https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.scorer\n",
      "Resolving github.com (github.com)... 140.82.114.3\n",
      "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/60273704/924cff80-3b0f-11eb-878c-cacaa2a0d946?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230906%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230906T061147Z&X-Amz-Expires=300&X-Amz-Signature=b0d3d86f4321c95501ac4069506efac548a44f2cdacb9b5381ce6666248cdc5a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=60273704&response-content-disposition=attachment%3B%20filename%3Ddeepspeech-0.9.3-models.scorer&response-content-type=application%2Foctet-stream [following]\n",
      "--2023-09-06 01:11:47--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/60273704/924cff80-3b0f-11eb-878c-cacaa2a0d946?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230906%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230906T061147Z&X-Amz-Expires=300&X-Amz-Signature=b0d3d86f4321c95501ac4069506efac548a44f2cdacb9b5381ce6666248cdc5a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=60273704&response-content-disposition=attachment%3B%20filename%3Ddeepspeech-0.9.3-models.scorer&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 953363776 (909M) [application/octet-stream]\n",
      "Saving to: ‘deepspeech-0.9.3-models.scorer.1’\n",
      "\n",
      "                dee  31%[=====>              ] 282.42M  36.8MB/s    eta 20s    ^C\n"
     ]
    }
   ],
   "source": [
    "# !wget https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.pbmm\n",
    "# !wget https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUDV3LjyzHlh"
   },
   "source": [
    "#### Importing Pkgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iJbnS-1Ifz1q"
   },
   "outputs": [],
   "source": [
    "from deepspeech import Model\n",
    "import numpy as np\n",
    "import os\n",
    "import wave\n",
    "\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzhFeNmvzWBW"
   },
   "source": [
    "#### Setting the environment and get an Istance of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RFUQHymqf_KH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow: v2.3.0-6-g23ad988\n",
      "DeepSpeech: v0.9.3-0-gf2e9c85\n",
      "2023-09-06 12:01:34.045497: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model_file_path = 'assets/deepspeech-0.9.3-models.pbmm'\n",
    "lm_file_path = 'assets/deepspeech-0.9.3-models.scorer'\n",
    "beam_width = 500\n",
    "lm_alpha = 0.93\n",
    "lm_beta = 1.18\n",
    "\n",
    "model = Model(model_file_path)\n",
    "model.enableExternalScorer(lm_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XU2fBnIfgLi3",
    "outputId": "657c0811-7f98-400d-ae3c-94cde80394e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.setScorerAlphaBeta(lm_alpha, lm_beta)\n",
    "model.setBeamWidth(beam_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47w35GzUzkqU"
   },
   "source": [
    "#### Batch Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "i2NQpZ-MgYpJ"
   },
   "outputs": [],
   "source": [
    "def read_wav_file(filename):\n",
    "    with wave.open(filename, 'rb') as w:\n",
    "        rate = w.getframerate()\n",
    "        frames = w.getnframes()\n",
    "        buffer = w.readframes(frames)\n",
    "        print(\"Rate:\", rate)\n",
    "        print(\"Frames:\", frames)\n",
    "        print(\"Buffer Len:\", len(buffer))\n",
    "\n",
    "    return buffer, rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Hozef1hPgzg5"
   },
   "outputs": [],
   "source": [
    "def transcribe_batch(audio_file):\n",
    "    buffer, rate = read_wav_file(audio_file)\n",
    "    data16 = np.frombuffer(buffer, dtype=np.int16)\n",
    "    return model.stt(data16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "QL_sz_SoiRz9",
    "outputId": "50064d63-ca9c-4291-cff2-73b5e828a4be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate: 44100\n",
      "Frames: 18024448\n",
      "Buffer Len: 72097792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i anandarupamamritam yad meditations adiantifolia a oratorical onepointedness saaamaaa tooanoowee italianate attainments attachments and eenamost aetiological italianate eighteenpennyworth anaesthesia i aesahhahiyenenhon anatomically athanasian are aeronautical teanaustaye attention iteration aeternitatis aneantissement asterotristia epithalamia teetotallers athanasian'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe_batch('assets/final.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7m_DuuHQzudM"
   },
   "source": [
    "#### Streaming Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTjPDSEf02Hy"
   },
   "source": [
    "#### Get a Stream Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "xGT6pW_Lz_8q"
   },
   "outputs": [],
   "source": [
    "stream = model.createStream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "yZfSy4n70_Qr"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def transcribe_streaming(audio_file):\n",
    "    buffer, rate = read_wav_file(audio_file)\n",
    "    offset=0\n",
    "    batch_size=50000\n",
    "    text=\"\"\n",
    "\n",
    "    while offset < len(buffer):\n",
    "      end_offset=offset+batch_size\n",
    "      chunk=buffer[offset:end_offset]\n",
    "      data16 = np.frombuffer(chunk, dtype=np.int16)\n",
    "\n",
    "      stream.feedAudioContent(data16)\n",
    "      text=stream.intermediateDecode()\n",
    "      clear_output(wait=True)\n",
    "      print(text)\n",
    "      offset=end_offset\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s-3emirD4wWS",
    "outputId": "853005cb-6d60-496b-9200-298c6e4b7ab4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i anandarupamamritam yad meditations adiantifolia a oratorical onepointedness saaamaaa tooanoowee italianate attainments attachments and eenamost aetiological italianate eighteenpennyworth anaesthesia i aesahhahiyenenhon anatomically athanasian are alone\n"
     ]
    }
   ],
   "source": [
    "transcribe_streaming('assets/final.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u9OC0XCa43zA",
    "outputId": "ef906445-ec2f-4fe7-b305-d5ebeed7a2d3"
   },
   "outputs": [],
   "source": [
    "transcribe_streaming('assets/speech_woman.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there and welcome to Improve Your Voice. My name is Darren McStay and today we're going to talk about learning to speak more clearly through daily practice. So every time I get a message relating to how someone can improve their voice, it's often followed by the assumption that they can get this quickly. Like there's quick fix of how to get this done. Unfortunately, with the voice, it doesn't really work like that. Your voice is created by your body using air, manipulated accordingly through intentions and impulses created by the mind. Your body is a physiological machine. It is an instrument made of muscle, bone, fascia and many other bits and bobs thrown in. If you want to train this instrument to perform better, then you are no different to an athlete who also has to train their body only. We're training our bodies in different ways. And of course, we all know that the smarter an athlete works and the more consistent they are with their work, the better they become. This means that if you want to create permanent and positive results which will ensure your instrument can function to the best of its ability, then you need to think and train like an athlete, okay? Not by using the same muscles the same way as an athlete, but you need to practice regularly and dare I say it, daily. Do you want to get better? Practice daily. Want to stop mumbling? Practice daily. Improve your confidence? Practice daily. Articulate better. Resonate more. Become more present? Practice daily. But most importantly, and according to the way this video is titled, if you want to be clearer and better understood, then you need to practice speaking clearer daily. So it's all very well taking the exercises from my channel and also from my online course, which are designed to make your instrument the best it can be. But if you're not practicing using that instrument, it's just going to start getting a bit rusty and a bit dusty. So even though it's a good instrument and it's in good shape, it still needs to be played. And what I mean by that is to become more mindful and more purposeful with how you speak daily. So in order for you to learn and to understand and start practicing speaking more clearly daily, I'm going to set you a task now, which you can start once this video is complete. I want you to go and find someone whose voice you like. Now, this could be a TV personality, a news reader, an actor, a politician, anyone that you know whose voice you can find in many places, be it on films, radio, cassette recordings, or anywhere you can find it on the internet, is a great source of material. Of course, find someone whose voice you would like to sound a bit like. And what I want you to do is find 30 to 60 seconds max recording and put it on your phone or your laptop of this person speaking. And what you're going to do is every day you're going to play that recording back, listen to it, stop it every few seconds and repeat what that person is saying exactly as you think they sound when they say it. Now, I think it's important that you find someone who you believe to be a good speaker, someone you find to be articulate and clear in their voice, not just someone you like their voice. If it's a singer, for example, if it's a mumble rapper, that's not going to get you anywhere with your articulation, clearer speech. So what you want to do is find someone who maybe uses their voice as a speaker for a living, possibly an actor, or, like I said before, a politician, and try to notice what it is that makes their voice stand out. What is it that makes it clear? And I don't want you to worry too much about this. I just want you to do it every day. Now, until you can impersonate the recording you have of this person, until you can actually do it the way they do it, I don't want you to think too much about what it is they're doing. I just want you to mimic the sounds they make. And there's a reason for this. When we're children, everything we learn is through copying, it's through mimicking. This is how we learn. And what happens is, as we get older, we form habits which aren't necessarily so good for our speech or good for our lives, even. So, what we need to do is to retrain our bodies, to start thinking and acting and copying those who we now wish to sound like or we now wish to become so specifically with our voices. Find someone who you want to sound like or believe that has a quality in their voice that you would like to have in yours, and we're going to start mimicking that. That's how we're going to learn. So if there's a lot of words in this text, you can stop it every few seconds and repeat after them. Or if it's just a short piece of text, maybe it's easy for you to learn it and repeat it back. And once you get to the point where you can remember everything that's great, keep doing it. Keep listening to the recording every day until you feel you can do a very good impersonation. Now, the best way for you to find out whether you're progressing and getting better with this is to record your own voice as well. And what you should do is if you do this listening exercise daily and speak along with it, then at the end of every week, you can record your voice and play that back against the other one and listen to yourself against how you sounded the week before. So you can do this for two weeks, a month, six months, a year, if you like, just do it until you're comfortable that something in your voice has changed. I don't want you to do this without using a warm up or some kind of physical exercises that get your body and your voice ready to speak. Now, you can do this one of three ways. I have tons of videos on this channel, and this one in particular is a great warm up. I'd like you to look at that every day before you do this exercise. So this way your body is in a really ready state to get started. And if you feel that after doing these exercises for, say, two weeks or a month, and doing these warm up exercises and the one I've set you, then I think you would be ready to check out the online course, do these exercises daily, go through all my videos, find everything you can practice daily, make something up. Maybe just do one video a day. Failing that, if you really don't want to do these exercises and you don't want to practice daily, you're not going to get as far as you want, as quick as you'd like. Of course, if you want to make permanent changes in your voice and permanent changes positive results from your instrument, then you need to do a very specific set of exercises. Which is why I put together my eight week online course. Because it took me 25 years to amass all that information and put it together in a structured way that I could teach others to literally transform their bodies from wherever they are into the ultimate speaking machine. But that aside, you have your task, whether you choose to take it or not. It's up to you. I hope you do. Thanks for joining me. My name is Darren McStay. This is improve your voice. And until the next time, practice using your voice.\n"
     ]
    }
   ],
   "source": [
    "import assemblyai as aai\n",
    "\n",
    "aai.settings.api_key = \"be696430f8d340289ff118b4ece0376b\"\n",
    "transcriber = aai.Transcriber()\n",
    "\n",
    "# transcript = transcriber.transcribe(\"https://storage.googleapis.com/aai-web-samples/news.mp4\")\n",
    "transcript = transcriber.transcribe(\"assets/final.wav\")\n",
    "\n",
    "print(transcript.text)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DeepSpeech.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
